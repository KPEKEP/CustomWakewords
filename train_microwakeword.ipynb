{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r11cNiLqvWC6"
   },
   "source": [
    "# Training a microWakeWord Model\n",
    "\n",
    "This notebook steps you through training a basic microWakeWord model. It is intended as a **starting point** for advanced users. You should use Python 3.10.\n",
    "\n",
    "**The model generated will most likely not be usable for everyday use; it may be difficult to trigger or falsely activates too frequently. You will most likely have to experiment with many different settings to obtain a decent model!**\n",
    "\n",
    "In the comment at the start of certain blocks, I note some specific settings to consider modifying.\n",
    "\n",
    "This runs on Google Colab, but is extremely slow compared to training on a local GPU. If you must use Colab, be sure to Change the runtime type to a GPU. Even then, it still slow!\n",
    "\n",
    "At the end of this notebook, you will be able to download a tflite file. To use this in ESPHome, you need to write a model manifest JSON file. See the [ESPHome documentation](https://esphome.io/components/micro_wake_word) for the details and the [model repo](https://github.com/esphome/micro-wake-word-models/tree/main/models/v2) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFf6511E65ff"
   },
   "outputs": [],
   "source": [
    "# Installs microWakeWord. Be sure to restart the session after this is finished.\n",
    "import platform\n",
    "\n",
    "if platform.system() == \"Darwin\":\n",
    "    # `pymicro-features` is installed from a fork to support building on macOS\n",
    "    !pip install 'git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version'\n",
    "\n",
    "# `audio-metadata` is installed from a fork to unpin `attrs` from a version that breaks Jupyter\n",
    "!pip install 'git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f'\n",
    "\n",
    "!git clone https://github.com/kahrendt/microWakeWord\n",
    "!pip install -e ./microWakeWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates 1 sample of the target word for manual verification.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "!rm -rf ./piper-sample-generator\n",
    "\n",
    "if not os.path.exists(\"./piper-sample-generator\"):\n",
    "    if platform.system() == \"Darwin\":\n",
    "        !git clone -b mps-support https://github.com/kahrendt/piper-sample-generator\n",
    "    else:\n",
    "        !git clone https://github.com/KPEKEP/piper-sample-generator\n",
    "\n",
    "    !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
    "\n",
    "    # Install system dependencies\n",
    "    !pip install torch torchaudio piper-phonemize-cross==1.2.1\n",
    "\n",
    "    if \"piper-sample-generator/\" not in sys.path:\n",
    "        sys.path.append(\"piper-sample-generator/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEluu7nL7ywd"
   },
   "outputs": [],
   "source": [
    "target_word = \"ˈsɜrjvɪtorj\"\n",
    "\n",
    "!python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
    "--phoneme \\\n",
    "--max-samples 1 \\\n",
    "--batch-size 1 \\\n",
    "--output-dir generated_samples \\\n",
    "--verbose\n",
    "\n",
    "Audio(\"generated_samples/0.wav\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SvGtCCM9akR"
   },
   "outputs": [],
   "source": [
    "# Generates a larger amount of wake word samples.\n",
    "# Start here when trying to improve your model.\n",
    "# See https://github.com/rhasspy/piper-sample-generator for the full set of\n",
    "# parameters. In particular, experiment with noise-scales and noise-scale-ws,\n",
    "# generating negative samples similar to the wake word, and generating many more\n",
    "# wake word samples, possibly with different phonetic pronunciations.\n",
    "\n",
    "!python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
    "--phoneme \\\n",
    "--max-samples 20000 \\\n",
    "--batch-size 100 \\\n",
    "--output-dir generated_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SvGtCCM9akR"
   },
   "outputs": [],
   "source": [
    "# Generate sound-a-like words for negative testing\n",
    "\n",
    "!python3 piper-sample-generator/generate_samples.py \"conservator\" \\\n",
    "--max-samples 10000 \\\n",
    "--batch-size 100 \\\n",
    "--output-dir negative_genrated_samples_1\n",
    "\n",
    "!python3 piper-sample-generator/generate_samples.py \"observator\" \\\n",
    "--max-samples 10000 \\\n",
    "--batch-size 100 \\\n",
    "--output-dir negative_genrated_samples_2\n",
    "\n",
    "!python3 piper-sample-generator/generate_samples.py \"server\" \\\n",
    "--max-samples 10000 \\\n",
    "--batch-size 100 \\\n",
    "--output-dir negative_genrated_samples_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJRG4Qvo9nXG"
   },
   "outputs": [],
   "source": [
    "# Downloads audio data for augmentation. This can be slow!\n",
    "# Borrowed from openWakeWord's automatic_model_training.ipynb, accessed March 4, 2024\n",
    "#\n",
    "# **Important note!** The data downloaded here has a mixture of difference\n",
    "# licenses and usage restrictions. As such, any custom models trained with this\n",
    "# data should be considered as appropriate for **non-commercial** personal use only.\n",
    "\n",
    "import datasets\n",
    "import scipy\n",
    "import os\n",
    "import shutil\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Download MIR RIR data\n",
    "\n",
    "shutil.rmtree(\"./mit_rirs\", ignore_errors=True)\n",
    "shutil.rmtree(\"./audioset\", ignore_errors=True)\n",
    "shutil.rmtree(\"./fma\", ignore_errors=True)\n",
    "\n",
    "output_dir = \"./mit_rirs\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "    # Load dataset with explicit Audio feature that doesn't use torchcodec\n",
    "    rir_dataset = datasets.load_dataset(\n",
    "        \"davidscripka/MIT_environmental_impulse_responses\", \n",
    "        split=\"train\", \n",
    "        streaming=True\n",
    "    ).cast_column(\"audio\", datasets.Audio(decode=True))\n",
    "    \n",
    "    # Process the data\n",
    "    for i, row in enumerate(tqdm(rir_dataset)):\n",
    "        try:\n",
    "            # Try to access audio data\n",
    "            audio_data = row['audio']\n",
    "            audio_array = audio_data['array']\n",
    "            sample_rate = audio_data['sampling_rate']\n",
    "            \n",
    "            # Generate filename\n",
    "            name = f\"rir_audio_{i:06d}.wav\"\n",
    "            \n",
    "            # Resample if needed\n",
    "            if sample_rate != 16000:\n",
    "                import librosa\n",
    "                audio_array = librosa.resample(audio_array, orig_sr=sample_rate, target_sr=16000)\n",
    "            \n",
    "            # Convert to 16-bit PCM\n",
    "            audio_int16 = (audio_array * 32767).astype(np.int16)\n",
    "            \n",
    "            # Save as wav file\n",
    "            scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, audio_int16)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "## Download noise and background audio\n",
    "\n",
    "# Audioset Dataset (https://research.google.com/audioset/dataset/index.html)\n",
    "# Download one part of the audioset .tar files, extract, and convert to 16khz\n",
    "# For full-scale training, it's recommended to download the entire dataset from\n",
    "# https://huggingface.co/datasets/agkphysics/AudioSet, and\n",
    "# even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)\n",
    "\n",
    "if not os.path.exists(\"audioset\"):\n",
    "    os.mkdir(\"audioset\")\n",
    "\n",
    "    fname = \"bal_train09.tar\"\n",
    "    out_dir = f\"audioset/{fname}\"\n",
    "    link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/\" + fname\n",
    "    !wget -O {out_dir} {link}\n",
    "    !cd audioset && tar -xf bal_train09.tar\n",
    "\n",
    "    output_dir = \"./audioset_16k\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    # Use librosa directly instead of datasets Audio to avoid torchcodec issues\n",
    "    audio_files = list(Path(\"audioset/audio\").glob(\"**/*.flac\"))\n",
    "    for audio_file in tqdm(audio_files):\n",
    "        try:\n",
    "            # Load audio with librosa\n",
    "            audio_array, sample_rate = librosa.load(str(audio_file), sr=16000)\n",
    "            \n",
    "            # Generate output filename\n",
    "            name = audio_file.name.replace(\".flac\", \".wav\")\n",
    "            \n",
    "            # Convert to 16-bit PCM\n",
    "            audio_int16 = (audio_array * 32767).astype(np.int16)\n",
    "            \n",
    "            # Save as wav file\n",
    "            scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, audio_int16)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Free Music Archive dataset\n",
    "# https://github.com/mdeff/fma\n",
    "# (Third-party mchl914 extra small set)\n",
    "\n",
    "output_dir = \"./fma\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    fname = \"fma_xs.zip\"\n",
    "    link = \"https://huggingface.co/datasets/mchl914/fma_xsmall/resolve/main/\" + fname\n",
    "    out_dir = f\"fma/{fname}\"\n",
    "    !wget -O {out_dir} {link}\n",
    "    !cd {output_dir} && unzip -q {fname}\n",
    "\n",
    "    output_dir = \"./fma_16k\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    # Use librosa directly instead of datasets Audio to avoid torchcodec issues\n",
    "    audio_files = list(Path(\"fma/fma_small\").glob(\"**/*.mp3\"))\n",
    "    for audio_file in tqdm(audio_files):\n",
    "        try:\n",
    "            # Load audio with librosa\n",
    "            audio_array, sample_rate = librosa.load(str(audio_file), sr=16000)\n",
    "            \n",
    "            # Generate output filename\n",
    "            name = audio_file.name.replace(\".mp3\", \".wav\")\n",
    "            \n",
    "            # Convert to 16-bit PCM\n",
    "            audio_int16 = (audio_array * 32767).astype(np.int16)\n",
    "            \n",
    "            # Save as wav file\n",
    "            scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, audio_int16)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_file}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW3bmbI5-JAz"
   },
   "outputs": [],
   "source": [
    "# Sets up the augmentations.\n",
    "# To improve your model, experiment with these settings and use more sources of\n",
    "# background clips.\n",
    "\n",
    "from microwakeword.audio.augmentation import Augmentation\n",
    "from microwakeword.audio.clips import Clips\n",
    "from microwakeword.audio.spectrograms import SpectrogramGeneration\n",
    "\n",
    "clips = Clips(input_directory='generated_samples',\n",
    "              file_pattern='*.wav',\n",
    "              max_clip_duration_s=None,\n",
    "              remove_silence=False,\n",
    "              random_split_seed=10,\n",
    "              split_count=0.1,\n",
    "              )\n",
    "augmenter = Augmentation(augmentation_duration_s=3.2,\n",
    "                         augmentation_probabilities = {\n",
    "                                \"SevenBandParametricEQ\": 0.1,\n",
    "                                \"TanhDistortion\": 0.1,\n",
    "                                \"PitchShift\": 0.1,\n",
    "                                \"BandStopFilter\": 0.1,\n",
    "                                \"AddColorNoise\": 0.1,\n",
    "                                \"AddBackgroundNoise\": 0.75,\n",
    "                                \"Gain\": 1.0,\n",
    "                                \"RIR\": 0.5,\n",
    "                            },\n",
    "                         impulse_paths = ['mit_rirs'],\n",
    "                         background_paths = ['fma_16k', 'audioset_16k'],\n",
    "                         background_min_snr_db = -5,\n",
    "                         background_max_snr_db = 10,\n",
    "                         min_jitter_s = 0.195,\n",
    "                         max_jitter_s = 0.205,\n",
    "                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microwakeword.audio.augmentation import Augmentation\n",
    "from microwakeword.audio.clips import Clips\n",
    "from microwakeword.audio.spectrograms import SpectrogramGeneration\n",
    "\n",
    "negative_clips = []\n",
    "negative_augmenters = []\n",
    "for i in range(1,4):\n",
    "    neg_clips = Clips(input_directory='negative_genrated_samples_'+str(i),\n",
    "                  file_pattern='*.wav',\n",
    "                  max_clip_duration_s=None,\n",
    "                  remove_silence=False,\n",
    "                  random_split_seed=10,\n",
    "                  split_count=0.1,\n",
    "                  )\n",
    "    neg_augmenter = Augmentation(augmentation_duration_s=3.2,\n",
    "                             augmentation_probabilities = {\n",
    "                                    \"SevenBandParametricEQ\": 0.1,\n",
    "                                    \"TanhDistortion\": 0.1,\n",
    "                                    \"PitchShift\": 0.1,\n",
    "                                    \"BandStopFilter\": 0.1,\n",
    "                                    \"AddColorNoise\": 0.1,\n",
    "                                    \"AddBackgroundNoise\": 0.75,\n",
    "                                    \"Gain\": 1.0,\n",
    "                                    \"RIR\": 0.5,\n",
    "                                },\n",
    "                             impulse_paths = ['mit_rirs'],\n",
    "                             background_paths = ['fma_16k', 'audioset_16k'],\n",
    "                             background_min_snr_db = -5,\n",
    "                             background_max_snr_db = 10,\n",
    "                             min_jitter_s = 0.195,\n",
    "                             max_jitter_s = 0.205,\n",
    "                             )\n",
    "    negative_clips.append(neg_clips)\n",
    "    negative_augmenters.append(neg_augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5UsJfKKD1k9"
   },
   "outputs": [],
   "source": [
    "# Augment a random clip and play it back to verify it works well\n",
    "\n",
    "from IPython.display import Audio\n",
    "from microwakeword.audio.audio_utils import save_clip\n",
    "\n",
    "random_clip = clips.get_random_clip()\n",
    "augmented_clip = augmenter.augment_clip(random_clip)\n",
    "save_clip(augmented_clip, 'augmented_clip.wav')\n",
    "\n",
    "Audio(\"augmented_clip.wav\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7BHcY1mEGbK"
   },
   "outputs": [],
   "source": [
    "# Augment samples and save the training, validation, and testing sets.\n",
    "# Validating and testing samples generated the same way can make the model\n",
    "# benchmark better than it performs in real-word use. Use real samples or TTS\n",
    "# samples generated with a different TTS engine to potentially get more accurate\n",
    "# benchmarks.\n",
    "\n",
    "import os\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "\n",
    "output_dir = 'generated_augmented_features'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "splits = [\"training\", \"validation\", \"testing\"]\n",
    "for split in splits:\n",
    "  out_dir = os.path.join(output_dir, split)\n",
    "  if not os.path.exists(out_dir):\n",
    "      os.mkdir(out_dir)\n",
    "\n",
    "\n",
    "  split_name = \"train\"\n",
    "  repetition = 2\n",
    "\n",
    "  spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                     augmenter=augmenter,\n",
    "                                     slide_frames=10,    # Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.\n",
    "                                     step_ms=10,\n",
    "                                     )\n",
    "  if split == \"validation\":\n",
    "    split_name = \"validation\"\n",
    "    repetition = 1\n",
    "  elif split == \"testing\":\n",
    "    split_name = \"test\"\n",
    "    repetition = 1\n",
    "    spectrograms = SpectrogramGeneration(clips=clips,\n",
    "                                     augmenter=augmenter,\n",
    "                                     slide_frames=1,    # The testing set uses the streaming version of the model, so no artificial repetition is necessary\n",
    "                                     step_ms=10,\n",
    "                                     )\n",
    "\n",
    "  RaggedMmap.from_generator(\n",
    "      out_dir=os.path.join(out_dir, 'wakeword_mmap'),\n",
    "      sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),\n",
    "      batch_size=100,\n",
    "      verbose=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D7BHcY1mEGbK"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eeb83cc97714d5e85a9e0859e9172cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffeea99e44cc414b9a595cd8f99b96cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d531b34d4947498e5c6cb12be9285e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f30c0e2df9425e892c5cf683d73b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070db3d9a84a48a69828661a27eecc03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af1ae0502124fb48d448616369f9dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b976497e83b5471ea0bc1cd8331715e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f96cb0b577e4fc5a6f9300461bd22e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a58baf6abd347a2a194bf75d2fe13a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from mmap_ninja.ragged import RaggedMmap\n",
    "\n",
    "output_dir = 'negative_generated_augmented_features'\n",
    "\n",
    "\n",
    "\n",
    "splits = [\"training\", \"validation\", \"testing\"]\n",
    "for split in splits:\n",
    "    for i in range(1,4):\n",
    "        numbered_dir = output_dir+\"_\"+str(i)\n",
    "        if not os.path.exists(numbered_dir):\n",
    "            os.mkdir(numbered_dir)        \n",
    "        out_dir = os.path.join(numbered_dir, split)\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "        \n",
    "        \n",
    "        split_name = \"train\"\n",
    "        repetition = 2\n",
    "        \n",
    "        spectrograms = SpectrogramGeneration(clips=negative_clips[i-1],\n",
    "                                         augmenter=negative_augmenters[i-1],\n",
    "                                         slide_frames=10,    # Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.\n",
    "                                         step_ms=10,\n",
    "                                         )\n",
    "        if split == \"validation\":\n",
    "            split_name = \"validation\"\n",
    "            repetition = 1\n",
    "        elif split == \"testing\":\n",
    "            split_name = \"test\"\n",
    "            repetition = 1\n",
    "            spectrograms = SpectrogramGeneration(clips=negative_clips[i-1],\n",
    "                                             augmenter=negative_augmenters[i-1],\n",
    "                                             slide_frames=1,    # The testing set uses the streaming version of the model, so no artificial repetition is necessary\n",
    "                                             step_ms=10,\n",
    "                                             )\n",
    "            \n",
    "        RaggedMmap.from_generator(\n",
    "          out_dir=os.path.join(out_dir, 'wakeword_mmap'),\n",
    "          sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),\n",
    "          batch_size=100,\n",
    "          verbose=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pGuJDPyp3ax"
   },
   "outputs": [],
   "source": [
    "# Downloads pre-generated spectrogram features (made for microWakeWord in\n",
    "# particular) for various negative datasets. This can be slow!\n",
    "\n",
    "output_dir = './negative_datasets'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    link_root = \"https://huggingface.co/datasets/kahrendt/microwakeword/resolve/main/\"\n",
    "    filenames = ['dinner_party.zip', 'dinner_party_eval.zip', 'no_speech.zip', 'speech.zip']\n",
    "    for fname in filenames:\n",
    "        link = link_root + fname\n",
    "\n",
    "        zip_path = f\"negative_datasets/{fname}\"\n",
    "        !wget -O {zip_path} {link}\n",
    "        !unzip -q {zip_path} -d {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ii1A14GsGVQT"
   },
   "outputs": [],
   "source": [
    "# Save a yaml config that controls the training process\n",
    "# These hyperparamters can make a huge different in model quality.\n",
    "# Experiment with sampling and penalty weights and increasing the number of\n",
    "# training steps.\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "config = {}\n",
    "\n",
    "config[\"window_step_ms\"] = 10\n",
    "\n",
    "config[\"train_dir\"] = (\n",
    "    \"trained_models/wakeword\"\n",
    ")\n",
    "\n",
    "\n",
    "# Each feature_dir should have at least one of the following folders with this structure:\n",
    "#  training/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  testing_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#  validation_ambient/\n",
    "#    ragged_mmap_folders_ending_in_mmap\n",
    "#\n",
    "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
    "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
    "#  truth: Boolean whether this set has positive samples or negative samples\n",
    "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
    "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
    "#       - truncate_start: remove the start of the spectrogram\n",
    "#       - truncate_end: remove the end of the spectrogram\n",
    "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
    "\n",
    "config[\"features\"] = [\n",
    "    {\n",
    "        \"features_dir\": \"generated_augmented_features\",\n",
    "        \"sampling_weight\": 2.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": True,\n",
    "        \"truncation_strategy\": \"truncate_start\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"negative_generated_augmented_features_1\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"negative_generated_augmented_features_2\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },    \n",
    "    {\n",
    "        \"features_dir\": \"negative_generated_augmented_features_3\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },        \n",
    "    {\n",
    "        \"features_dir\": \"negative_datasets/speech\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"negative_datasets/dinner_party\",\n",
    "        \"sampling_weight\": 10.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    {\n",
    "        \"features_dir\": \"negative_datasets/no_speech\",\n",
    "        \"sampling_weight\": 5.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"random\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "    { # Only used for validation and testing\n",
    "        \"features_dir\": \"negative_datasets/dinner_party_eval\",\n",
    "        \"sampling_weight\": 0.0,\n",
    "        \"penalty_weight\": 1.0,\n",
    "        \"truth\": False,\n",
    "        \"truncation_strategy\": \"split\",\n",
    "        \"type\": \"mmap\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
    "config[\"training_steps\"] = [2000] # [10000]\n",
    "\n",
    "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
    "config[\"positive_class_weight\"] = [1]\n",
    "config[\"negative_class_weight\"] = [20]\n",
    "\n",
    "config[\"learning_rates\"] = [\n",
    "    0.001,\n",
    "]  # Learning rates for Adam optimizer - list that corresponds to training steps\n",
    "config[\"batch_size\"] = 128\n",
    "\n",
    "config[\"time_mask_max_size\"] = [\n",
    "    0\n",
    "]  # SpecAugment - list that corresponds to training steps\n",
    "config[\"time_mask_count\"] = [0]  # SpecAugment - list that corresponds to training steps\n",
    "config[\"freq_mask_max_size\"] = [\n",
    "    0\n",
    "]  # SpecAugment - list that corresponds to training steps\n",
    "config[\"freq_mask_count\"] = [0]  # SpecAugment - list that corresponds to training steps\n",
    "\n",
    "config[\"eval_step_interval\"] = (\n",
    "    500  # Test the validation sets after every this many steps\n",
    ")\n",
    "config[\"clip_duration_ms\"] = (\n",
    "    2100  # Maximum length of wake word that the streaming model will accept\n",
    ")\n",
    "\n",
    "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
    "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
    "# Available metrics:\n",
    "#   - \"loss\" - cross entropy error on validation set\n",
    "#   - \"accuracy\" - accuracy of validation set\n",
    "#   - \"recall\" - recall of validation set\n",
    "#   - \"precision\" - precision of validation set\n",
    "#   - \"false_positive_rate\" - false positive rate of validation set\n",
    "#   - \"false_negative_rate\" - false negative rate of validation set\n",
    "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
    "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
    "config[\"target_minimization\"] = 0.9\n",
    "config[\"minimization_metric\"] = None  # Set to None to disable\n",
    "\n",
    "config[\"maximization_metric\"] = \"average_viable_recall\"\n",
    "\n",
    "with open(os.path.join(\"training_parameters.yaml\"), \"w\") as file:\n",
    "    documents = yaml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WoEXJBaiC9mf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-25 17:41:07.663276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753458067.681765    6447 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753458067.687100    6447 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753458067.701350    6447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753458067.701375    6447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753458067.701379    6447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753458067.701399    6447 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-25 17:41:07.705427: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-25 17:41:10.231358: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-07-25 17:41:10.231388: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:167] env: CUDA_VISIBLE_DEVICES=\"-1\"\n",
      "2025-07-25 17:41:10.231404: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] CUDA_VISIBLE_DEVICES is set to -1 - this hides all GPUs from CUDA\n",
      "2025-07-25 17:41:10.231415: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-07-25 17:41:10.231454: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: homebase\n",
      "2025-07-25 17:41:10.231473: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: homebase\n",
      "2025-07-25 17:41:10.231604: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 535.247.1\n",
      "2025-07-25 17:41:10.231634: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 535.247.1\n",
      "2025-07-25 17:41:10.231644: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 535.247.1\n",
      "INFO:absl:Loading and analyzing data sets.\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 22\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 51\n",
      "\u001b[1mModel: \"functional\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer         │ (\u001b[32m128\u001b[0m, \u001b[32m208\u001b[0m, \u001b[32m40\u001b[0m)    │          \u001b[32m0\u001b[0m │ -                 │\n",
      "│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expand_dims         │ (\u001b[32m128\u001b[0m, \u001b[32m208\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m40\u001b[0m) │          \u001b[32m0\u001b[0m │ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "│ (\u001b[94mExpandDims\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream (\u001b[94mStream\u001b[0m)     │ (\u001b[32m128\u001b[0m, \u001b[32m102\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m) │      \u001b[32m6,400\u001b[0m │ expand_dims[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation          │ (\u001b[32m128\u001b[0m, \u001b[32m102\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m) │          \u001b[32m0\u001b[0m │ stream[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_1 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m102\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m) │          \u001b[32m0\u001b[0m │ activation[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d    │ (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │        \u001b[32m192\u001b[0m │ stream_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_1 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │      \u001b[32m2,048\u001b[0m │ depthwise_conv2d… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalization │ (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │        \u001b[32m256\u001b[0m │ conv2d_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_1        │ (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_2 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ activation_1[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ channel_split       │ [(\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m,     │          \u001b[32m0\u001b[0m │ stream_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mChannelSplit\u001b[0m)      │ \u001b[32m32\u001b[0m), (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, │            │                   │\n",
      "│                     │ \u001b[32m32\u001b[0m)]              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep        │ (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ channel_split[\u001b[32m0\u001b[0m]… │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_1      │ (\u001b[32m128\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ channel_split[\u001b[32m0\u001b[0m]… │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_1  │ (\u001b[32m128\u001b[0m, \u001b[32m92\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │        \u001b[32m256\u001b[0m │ strided_keep[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_2  │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │        \u001b[32m384\u001b[0m │ strided_keep_1[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop        │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_1      │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ concatenate         │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ strided_drop[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ strided_drop_1[\u001b[32m0\u001b[0m… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_2 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │      \u001b[32m4,096\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │        \u001b[32m256\u001b[0m │ conv2d_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_2        │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_3 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ activation_2[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ channel_split_1     │ [(\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m,     │          \u001b[32m0\u001b[0m │ stream_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mChannelSplit\u001b[0m)      │ \u001b[32m32\u001b[0m), (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, │            │                   │\n",
      "│                     │ \u001b[32m32\u001b[0m)]              │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_2      │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ channel_split_1[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_3      │ (\u001b[32m128\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ channel_split_1[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_3  │ (\u001b[32m128\u001b[0m, \u001b[32m80\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │        \u001b[32m320\u001b[0m │ strided_keep_2[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_4  │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │        \u001b[32m512\u001b[0m │ strided_keep_3[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_2      │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_3      │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)  │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ concatenate_1       │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ strided_drop_2[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ strided_drop_3[\u001b[32m0\u001b[0m… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_3 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │      \u001b[32m4,096\u001b[0m │ concatenate_1[\u001b[32m0\u001b[0m]… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │        \u001b[32m256\u001b[0m │ conv2d_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_3        │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_4 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ activation_3[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_5  │ (\u001b[32m128\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │      \u001b[32m1,536\u001b[0m │ stream_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_4 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │      \u001b[32m4,096\u001b[0m │ depthwise_conv2d… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m128\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │        \u001b[32m256\u001b[0m │ conv2d_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_4        │ (\u001b[32m128\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_5 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)  │          \u001b[32m0\u001b[0m │ activation_4[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ flatten (\u001b[94mFlatten\u001b[0m)   │ (\u001b[32m128\u001b[0m, \u001b[32m3328\u001b[0m)       │          \u001b[32m0\u001b[0m │ stream_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ dense (\u001b[94mDense\u001b[0m)       │ (\u001b[32m128\u001b[0m, \u001b[32m1\u001b[0m)          │      \u001b[32m3,329\u001b[0m │ flatten[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n",
      "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m28,289\u001b[0m (110.50 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m27,777\u001b[0m (108.50 KB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m512\u001b[0m (2.00 KB)\n",
      "INFO:absl:None\n",
      "INFO:absl:Step #500: rate 0.001000, accuracy 98.75%, recall 76.08%, precision 87.11%, cross entropy 0.039135\n",
      "2025-07-25 18:06:43.515727: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5791651840 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Step 500 (nonstreaming): Validation: recall at no faph = 0.000 with cutoff 1.00, accuracy = 96.89%, recall = 93.60%, precision = 83.20%, ambient false positives = 601, estimated false positives per hour = 62.14793, loss = 0.02510, auc = 0.99407, average viable recall = 0.620802704\n",
      "INFO:absl:Sharding callback duration: 75 microseconds\n",
      "INFO:absl:So far the best minimization quantity is 0.000 with best maximization quantity of 62.08027%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #1000: rate 0.001000, accuracy 99.61%, recall 92.90%, precision 95.99%, cross entropy 0.012162\n",
      "2025-07-25 18:48:55.316729: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5791651840 exceeds 10% of free system memory.\n",
      "INFO:absl:Step 1000 (nonstreaming): Validation: recall at no faph = 0.000 with cutoff 1.00, accuracy = 95.99%, recall = 97.62%, precision = 76.34%, ambient false positives = 655, estimated false positives per hour = 67.73193, loss = 0.02868, auc = 0.99720, average viable recall = 0.203958139\n",
      "INFO:absl:So far the best minimization quantity is 0.000 with best maximization quantity of 62.08027%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #1500: rate 0.001000, accuracy 99.69%, recall 94.53%, precision 96.82%, cross entropy 0.009562\n",
      "2025-07-25 19:33:01.798968: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5791651840 exceeds 10% of free system memory.\n",
      "INFO:absl:Step 1500 (nonstreaming): Validation: recall at no faph = 0.000 with cutoff 1.00, accuracy = 98.53%, recall = 92.43%, precision = 95.45%, ambient false positives = 108, estimated false positives per hour = 11.16801, loss = 0.00921, auc = 0.99491, average viable recall = 0.693480593\n",
      "INFO:absl:Sharding callback duration: 51335 microseconds\n",
      "INFO:absl:So far the best minimization quantity is 0.000 with best maximization quantity of 69.34806%; no faph cutoff is 1.00\n",
      "INFO:absl:Step #2000: rate 0.001000, accuracy 99.73%, recall 94.87%, precision 97.35%, cross entropy 0.007965\n",
      "2025-07-25 20:15:31.483452: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5791651840 exceeds 10% of free system memory.\n",
      "INFO:absl:Step 2000 (nonstreaming): Validation: recall at no faph = 0.000 with cutoff 1.00, accuracy = 99.33%, recall = 97.43%, precision = 97.10%, ambient false positives = 173, estimated false positives per hour = 17.88950, loss = 0.00672, auc = 0.99827, average viable recall = 0.859513086\n",
      "INFO:absl:Sharding callback duration: 12327 microseconds\n",
      "INFO:absl:So far the best minimization quantity is 0.000 with best maximization quantity of 85.95131%; no faph cutoff is 1.00\n",
      "INFO:absl:Sharding callback duration: 36 microseconds\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 22\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 51\n",
      "\u001b[1mModel: \"functional_1\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_layer_1       │ (\u001b[32m1\u001b[0m, \u001b[32m208\u001b[0m, \u001b[32m40\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n",
      "│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expand_dims_1       │ (\u001b[32m1\u001b[0m, \u001b[32m208\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m40\u001b[0m)   │          \u001b[32m0\u001b[0m │ input_layer_1[\u001b[32m0\u001b[0m]… │\n",
      "│ (\u001b[94mExpandDims\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_6 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m102\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)   │      \u001b[32m6,400\u001b[0m │ expand_dims_1[\u001b[32m0\u001b[0m]… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_5        │ (\u001b[32m1\u001b[0m, \u001b[32m102\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)   │          \u001b[32m0\u001b[0m │ stream_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_7 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m102\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)   │          \u001b[32m0\u001b[0m │ activation_5[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_6  │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │        \u001b[32m192\u001b[0m │ stream_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_6 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │      \u001b[32m2,048\u001b[0m │ depthwise_conv2d… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │        \u001b[32m256\u001b[0m │ conv2d_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼──��────────────────┼────────────┼───────────────────┤\n",
      "│ activation_6        │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_8 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ activation_6[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ channel_split_2     │ [(\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m),  │          \u001b[32m0\u001b[0m │ stream_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mChannelSplit\u001b[0m)      │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)]   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_4      │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ channel_split_2[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_5      │ (\u001b[32m1\u001b[0m, \u001b[32m98\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ channel_split_2[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_7  │ (\u001b[32m1\u001b[0m, \u001b[32m92\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │        \u001b[32m256\u001b[0m │ strided_keep_4[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_8  │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │        \u001b[32m384\u001b[0m │ strided_keep_5[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_4      │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_5      │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ concatenate_2       │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ strided_drop_4[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ strided_drop_5[\u001b[32m0\u001b[0m… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_7 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │      \u001b[32m4,096\u001b[0m │ concatenate_2[\u001b[32m0\u001b[0m]… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │        \u001b[32m256\u001b[0m │ conv2d_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_7        │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_9 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ activation_7[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ channel_split_3     │ [(\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m),  │          \u001b[32m0\u001b[0m │ stream_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mChannelSplit\u001b[0m)      │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)]   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_6      │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ channel_split_3[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_7      │ (\u001b[32m1\u001b[0m, \u001b[32m88\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ channel_split_3[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_9  │ (\u001b[32m1\u001b[0m, \u001b[32m80\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │        \u001b[32m320\u001b[0m │ strided_keep_6[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_10 │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │        \u001b[32m512\u001b[0m │ strided_keep_7[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_6      │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_7      │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ concatenate_3       │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ strided_drop_6[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ strided_drop_7[\u001b[32m0\u001b[0m… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_8 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │      \u001b[32m4,096\u001b[0m │ concatenate_3[\u001b[32m0\u001b[0m]… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │        \u001b[32m256\u001b[0m │ conv2d_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_8        │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_10 (\u001b[94mStream\u001b[0m)  │ (\u001b[32m1\u001b[0m, \u001b[32m74\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ activation_8[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_11 │ (\u001b[32m1\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │      \u001b[32m1,536\u001b[0m │ stream_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_9 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │      \u001b[32m4,096\u001b[0m │ depthwise_conv2d… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │        \u001b[32m256\u001b[0m │ conv2d_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_9        │ (\u001b[32m1\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_11 (\u001b[94mStream\u001b[0m)  │ (\u001b[32m1\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │          \u001b[32m0\u001b[0m │ activation_9[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ flatten_1 (\u001b[94mFlatten\u001b[0m) │ (\u001b[32m1\u001b[0m, \u001b[32m3328\u001b[0m)         │          \u001b[32m0\u001b[0m │ stream_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ dense_1 (\u001b[94mDense\u001b[0m)     │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m)            │      \u001b[32m3,329\u001b[0m │ flatten_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
      "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m28,289\u001b[0m (110.50 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m27,777\u001b[0m (108.50 KB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m512\u001b[0m (2.00 KB)\n",
      "INFO:absl:None\n",
      "INFO:absl:Saving streaming model\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 3\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 10\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 14\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 22\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 51\n",
      "\u001b[1mModel: \"functional_1\"\u001b[0m\n",
      "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
      "│ input_audio         │ (\u001b[32m1\u001b[0m, \u001b[32m2\u001b[0m, \u001b[32m40\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n",
      "│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ expand_dims_2       │ (\u001b[32m1\u001b[0m, \u001b[32m2\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m40\u001b[0m)     │          \u001b[32m0\u001b[0m │ input_audio[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n",
      "│ (\u001b[94mExpandDims\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_6 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │      \u001b[32m6,520\u001b[0m │ expand_dims_2[\u001b[32m0\u001b[0m]… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_5        │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │          \u001b[32m0\u001b[0m │ stream_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_7 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m5\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │        \u001b[32m128\u001b[0m │ activation_5[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_6  │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │        \u001b[32m192\u001b[0m │ stream_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_6 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │      \u001b[32m2,048\u001b[0m │ depthwise_conv2d… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m256\u001b[0m │ conv2d_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_6        │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_8 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m11\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │        \u001b[32m640\u001b[0m │ activation_6[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ channel_split_2     │ [(\u001b[32m1\u001b[0m, \u001b[32m11\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m),  │          \u001b[32m0\u001b[0m │ stream_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mChannelSplit\u001b[0m)      │ (\u001b[32m1\u001b[0m, \u001b[32m11\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)]   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_4      │ (\u001b[32m1\u001b[0m, \u001b[32m7\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │          \u001b[32m0\u001b[0m │ channel_split_2[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_5      │ (\u001b[32m1\u001b[0m, \u001b[32m11\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ channel_split_2[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_7  │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │        \u001b[32m256\u001b[0m │ strided_keep_4[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_8  │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │        \u001b[32m384\u001b[0m │ strided_keep_5[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_4      │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_5      │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ concatenate_2       │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │          \u001b[32m0\u001b[0m │ strided_drop_4[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ strided_drop_5[\u001b[32m0\u001b[0m… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_7 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │      \u001b[32m4,096\u001b[0m │ concatenate_2[\u001b[32m0\u001b[0m]… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m256\u001b[0m │ conv2d_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_7        │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_9 (\u001b[94mStream\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m15\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │        \u001b[32m896\u001b[0m │ activation_7[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ channel_split_3     │ [(\u001b[32m1\u001b[0m, \u001b[32m15\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m),  │          \u001b[32m0\u001b[0m │ stream_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mChannelSplit\u001b[0m)      │ (\u001b[32m1\u001b[0m, \u001b[32m15\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)]   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_6      │ (\u001b[32m1\u001b[0m, \u001b[32m9\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │          \u001b[32m0\u001b[0m │ channel_split_3[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_keep_7      │ (\u001b[32m1\u001b[0m, \u001b[32m15\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)    │          \u001b[32m0\u001b[0m │ channel_split_3[\u001b[32m…\u001b[0m │\n",
      "│ (\u001b[94mStridedKeep\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_9  │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │        \u001b[32m320\u001b[0m │ strided_keep_6[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_10 │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │        \u001b[32m512\u001b[0m │ strided_keep_7[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_6      │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ strided_drop_7      │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m32\u001b[0m)     │          \u001b[32m0\u001b[0m │ depthwise_conv2d… │\n",
      "│ (\u001b[94mStridedDrop\u001b[0m)       │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ concatenate_3       │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │          \u001b[32m0\u001b[0m │ strided_drop_6[\u001b[32m0\u001b[0m… │\n",
      "│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ strided_drop_7[\u001b[32m0\u001b[0m… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_8 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │      \u001b[32m4,096\u001b[0m │ concatenate_3[\u001b[32m0\u001b[0m]… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m256\u001b[0m │ conv2d_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_8        │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_10 (\u001b[94mStream\u001b[0m)  │ (\u001b[32m1\u001b[0m, \u001b[32m23\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │      \u001b[32m1,408\u001b[0m │ activation_8[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ depthwise_conv2d_11 │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │      \u001b[32m1,536\u001b[0m │ stream_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
      "│ (\u001b[94mDepthwiseConv2D\u001b[0m)   │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ conv2d_9 (\u001b[94mConv2D\u001b[0m)   │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │      \u001b[32m4,096\u001b[0m │ depthwise_conv2d… │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ batch_normalizatio… │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │        \u001b[32m256\u001b[0m │ conv2d_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n",
      "│ (\u001b[94mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ activation_9        │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)     │          \u001b[32m0\u001b[0m │ batch_normalizat… │\n",
      "│ (\u001b[94mActivation\u001b[0m)        │                   │            │                   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ stream_11 (\u001b[94mStream\u001b[0m)  │ (\u001b[32m1\u001b[0m, \u001b[32m52\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m64\u001b[0m)    │      \u001b[32m3,264\u001b[0m │ activation_9[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ flatten_1 (\u001b[94mFlatten\u001b[0m) │ (\u001b[32m1\u001b[0m, \u001b[32m3328\u001b[0m)         │          \u001b[32m0\u001b[0m │ stream_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
      "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
      "│ dense_1 (\u001b[94mDense\u001b[0m)     │ (\u001b[32m1\u001b[0m, \u001b[32m1\u001b[0m)            │      \u001b[32m3,329\u001b[0m │ flatten_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n",
      "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "\u001b[1m Total params: \u001b[0m\u001b[32m34,745\u001b[0m (135.72 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[32m27,777\u001b[0m (108.50 KB)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m6,968\u001b[0m (27.22 KB)\n",
      "INFO:absl:Function `call` contains input name(s) resource with unsupported characters which will be renamed to dense_1_1_add_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Function `call` contains input name(s) resource with unsupported characters which will be renamed to dense_1_1_add_readvariableop_resource in the SavedModel.\n",
      "INFO:absl:Sharding callback duration: 80 microseconds\n",
      "INFO:absl:Sharding callback duration: 36 microseconds\n",
      "INFO:absl:Writing fingerprint to trained_models/wakeword/stream_state_internal/fingerprint.pb\n",
      "Saved artifact at 'trained_models/wakeword/stream_state_internal'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  inputs (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(1, 2, 40), dtype=tf.float32, name=None)\n",
      "  training (POSITIONAL_OR_KEYWORD): Literal[None]\n",
      "  mask (POSITIONAL_OR_KEYWORD): Literal[None]\n",
      "Output Type:\n",
      "  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  136984047939856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984500102320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047928944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047841376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047832224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047844544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047840848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047938448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047941440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047830464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065656608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984047831168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065668928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065669456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065665056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065669632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065710512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065706992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065706816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065709808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065712624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065713680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066497824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984065717376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066495008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066505744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066446384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066442864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066442688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066445680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066447440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066456240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066453072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066456768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066444096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066449376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066327824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066330816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066327472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066337680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  136984066338384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "INFO:absl:Converting quantized streaming model to TFLite\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1753468016.362418    6447 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1753468016.422334    6447 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-07-25 20:26:56.632697: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: trained_models/wakeword/stream_state_internal\n",
      "2025-07-25 20:26:56.654541: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-07-25 20:26:56.654566: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: trained_models/wakeword/stream_state_internal\n",
      "I0000 00:00:1753468016.861384    6447 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2025-07-25 20:26:56.907720: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-07-25 20:26:57.359006: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: trained_models/wakeword/stream_state_internal\n",
      "2025-07-25 20:26:57.399095: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 762336 microseconds.\n",
      "2025-07-25 20:27:00.230911: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-25 20:27:04.056702: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:4061] Estimated count of arithmetic ops: 0.055 M  ops, equivalently 0.027 M  MACs\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: UINT8\n",
      "2025-07-25 20:27:50.071397: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:4061] Estimated count of arithmetic ops: 0.055 M  ops, equivalently 0.027 M  MACs\n",
      "INFO:absl:Testing the TFLite quantized streaming model false accept per hour and false rejection rates at various cutoffs.\n",
      "UserWarning:\n",
      "        Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "        TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "        See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "        for details.\n",
      "        \n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO:absl:Testing the testing_ambient set.\n",
      "INFO:absl:Testing the testing set.\n",
      "INFO:absl:AUC 0.50810\n",
      "INFO:absl:Cutoff 1.00: frr=1.0000; faph=0.000\n",
      "INFO:absl:Cutoff 0.99: frr=0.0905; faph=0.750\n",
      "INFO:absl:Cutoff 0.98: frr=0.0833; faph=1.125\n",
      "INFO:absl:Cutoff 0.97: frr=0.0762; faph=1.687\n",
      "INFO:absl:Cutoff 0.96: frr=0.0690; faph=1.875\n",
      "INFO:absl:Cutoff 0.96: frr=0.0619; faph=2.000\n"
     ]
    }
   ],
   "source": [
    "# Trains a model. When finished, it will quantize and convert the model to a\n",
    "# streaming version suitable for on-device detection.\n",
    "# It will resume if stopped, but it will start over at the configured training\n",
    "# steps in the yaml file.\n",
    "# Change --train 0 to only convert and test the best-weighted model.\n",
    "# On Google colab, it doesn't print the mini-batch results, so it may appear\n",
    "# stuck for several minutes! Additionally, it is very slow compared to training\n",
    "# on a local GPU.\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=-1 python -m microwakeword.model_train_eval \\\n",
    "--training_config='training_parameters.yaml' \\\n",
    "--train 1 \\\n",
    "--restore_checkpoint 0 \\\n",
    "--test_tf_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming 0 \\\n",
    "--test_tflite_nonstreaming_quantized 0 \\\n",
    "--test_tflite_streaming 0 \\\n",
    "--test_tflite_streaming_quantized 1 \\\n",
    "--use_weights \"best_weights\" \\\n",
    "mixednet \\\n",
    "--pointwise_filters \"64,64,64,64\" \\\n",
    "--repeat_in_block  \"1, 1, 1, 1\" \\\n",
    "--mixconv_kernel_sizes '[5], [7,11], [9,15], [23]' \\\n",
    "--residual_connection \"0,0,0,0\" \\\n",
    "--first_conv_filters 32 \\\n",
    "--first_conv_kernel_size 5 \\\n",
    "--stride 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ex_UIWvwtjAN"
   },
   "outputs": [],
   "source": [
    "# Downloads the tflite model file. To use on the device, you need to write a\n",
    "# Model JSON file. See https://esphome.io/components/micro_wake_word for the\n",
    "# documentation and\n",
    "# https://github.com/esphome/micro-wake-word-models/tree/main/models/v2 for\n",
    "# examples. Adjust the probability threshold based on the test results obtained\n",
    "# after training is finished. You may also need to increase the Tensor arena\n",
    "# model size if the model fails to load.--verbosity\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "files.download(f\"trained_models/wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
